{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[1] = 'trainingSet.csv'\n",
    "sys.argv[2] = 'testSet.csv'\n",
    "\n",
    "trainingDataFilename = sys.argv[1]\n",
    "testDataFilename = sys.argv[2]\n",
    "# modelIdx = int(sys.argv[3])\n",
    "modelIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_LIMIT = 8\n",
    "SAMPLE_LIMIT = 50\n",
    "def class TreeNode(object):\n",
    "    def __init__(self, class_label, lineage):\n",
    "        \"\"\"Node constructor\n",
    "            @param class_label: class label which this leaf node predicts\n",
    "            For non-leaf nodes:\n",
    "                self.val holds the index of feature on which the node splits\n",
    "            For leaf nodes:\n",
    "                self.val holds the class label which it predicts\n",
    "        \"\"\"\n",
    "        self.val = class_label\n",
    "        self.lineage = lineage\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        \"\"\"Returns: bool: True when node is leaf, False otherwise\n",
    "        \"\"\"\n",
    "        return ((self.left is None) or (self.right is None))\n",
    "\n",
    "    def expand(self, data, features, N,\n",
    "               depth=DEFAULT_TREE_DEPTH, downsampling_power=1):\n",
    "        \"\"\"Adds 2 children by following splitting criteria\n",
    "        \"\"\"\n",
    "        if not len(data):  # No data given\n",
    "            self.val = -1\n",
    "            return\n",
    "        class_col = [row[-2] for row in data]\n",
    "        class_label = int(class_col.count(1) > class_col.count(0))\n",
    "        eligible_features = [f for f in features if f not in self.lineage]\n",
    "        available_features = \\\n",
    "            sample(eligible_features,\n",
    "                   int(round(len(eligible_features)**downsampling_power)))\n",
    "        if len(self.lineage) <= depth \\\n",
    "           and (sum([row[-3] for row in data]) * N) > 9 \\\n",
    "           and len(available_features) > 0:  # eligible non-leaf node\n",
    "            ginis = {i: gini(data, i) for i in available_features}\n",
    "            split_idx = min(ginis, key=ginis.get)\n",
    "            left_data = [row for row in data if row[split_idx] == 0]\n",
    "            right_data = [row for row in data if row[split_idx] == 1]\n",
    "            if sum([r[-3] for r in left_data]) and \\\n",
    "               sum([r[-3] for r in right_data]):  # Confirmed non-leaf node\n",
    "                self.val = split_idx\n",
    "                self.left = TreeNode(class_label, self.lineage + [split_idx])\n",
    "                self.left.expand(left_data, features, N, depth=depth,\n",
    "                                 downsampling_power=downsampling_power)\n",
    "                self.right = TreeNode(class_label, self.lineage + [split_idx])\n",
    "                self.right.expand(right_data, features, N, depth=depth,\n",
    "                                  downsampling_power=downsampling_power)\n",
    "            else:\n",
    "                self.val = class_label\n",
    "        else:\n",
    "            self.val = class_label\n",
    "def gini(data, attr):\n",
    "    gini = 0.0\n",
    "    total = len(data)\n",
    "    pos = 1.0 * data[attr].value_counts()[0]/total\n",
    "    neg = 1.0 * data[attr].value_counts()[1]/total\n",
    "\n",
    "    return 1 - pos ** 2 - neg ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(trainingSet, testSet):\n",
    "    print 'decisionTree'\n",
    "    print gini(trainingSet, 'decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(trainingSet, testSet):\n",
    "    print 'bagging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForests(trainingSet, testSet):\n",
    "    print 'randomForests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "decisionTree\n",
      "0.4921875\n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "keys = trainingSet.keys()\n",
    "keys = keys.drop('decision')\n",
    "\n",
    "if modelIdx == 1:\n",
    "#     for \n",
    "    decisionTree(trainingSet, testSet)\n",
    "elif modelIdx == 2:\n",
    "    bagging(trainingSet, testSet)\n",
    "elif modelIdx == 3:\n",
    "    randomForests(trainingSet, testSet)\n",
    "else:\n",
    "    print 'modelIdx error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
