{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[1] = 'trainingSet.csv'\n",
    "sys.argv[2] = 'testSet.csv'\n",
    "\n",
    "trainingDataFilename = sys.argv[1]\n",
    "testDataFilename = sys.argv[2]\n",
    "# modelIdx = int(sys.argv[3])\n",
    "modelIdx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_LIMIT = 8\n",
    "SAMPLE_LIMIT = 50\n",
    "class TreeNode(object):\n",
    "    def __init__(self, class_label, lineage):\n",
    "        self.val = class_label\n",
    "        self.lineage = lineage\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return ((self.left is None) or (self.right is None))\n",
    "\n",
    "    def expand(self, data, features, modelIdx, depth=DEPTH_LIMIT):\n",
    "        class_label = int(len(data[data['decision'] == 1]) > len(data[data['decision'] == 0]))\n",
    "        if modelIdx == 1 or modelIdx == 2:\n",
    "            available_features = [f for f in features if f not in self.lineage]\n",
    "        else:\n",
    "            rf_sample = [i for i in range(0, int(len(features)))]\n",
    "            np.random.shuffle(rf_sample)\n",
    "            rf_sample = rf_sample[0:int(np.sqrt(len(features)))]\n",
    "            rf_features = []\n",
    "            for i in rf_sample:\n",
    "                rf_features.append(features[i])\n",
    "            #print rf_features\n",
    "            available_features = [f for f in rf_features if f not in self.lineage]\n",
    "        if len(self.lineage) < depth - 1 and len(data) > 50:\n",
    "            ginis = {k: get_gini_gain(data, k) for k in available_features}\n",
    "            best_feature = max(ginis, key=ginis.get)\n",
    "            left_data = data[data[best_feature] == 0]\n",
    "            right_data = data[data[best_feature] == 1]\n",
    "            \n",
    "            self.val = best_feature\n",
    "            self.left = TreeNode(class_label, self.lineage + [best_feature])\n",
    "            self.left.expand(left_data, features, modelIdx, depth=depth)\n",
    "            self.right = TreeNode(class_label, self.lineage + [best_feature])\n",
    "            self.right.expand(right_data, features, modelIdx, depth=depth)\n",
    "        else:\n",
    "            self.val = class_label\n",
    "            \n",
    "def gini(data):\n",
    "    total = len(data)\n",
    "    pos = 1.0 * len(data[data['decision'] == 1])/(1.0 * total) if len(data[data['decision'] == 1]) > 0 else 0.0\n",
    "    neg = 1.0 * len(data[data['decision'] == 0])/(1.0 * total) if len(data[data['decision'] == 0]) > 0 else 0.0\n",
    "    return 1.0 - pos * pos - neg * neg\n",
    "\n",
    "def get_gini_gain(data, attr):\n",
    "    total = len(data)\n",
    "    pos = 1.0 * len(data[data[attr] == 1])/(1.0 * total) if len(data[data[attr] == 1]) > 0 else 0.0\n",
    "    neg = 1.0 * len(data[data[attr] == 0])/(1.0 * total) if len(data[data[attr] == 0]) > 0 else 0.0\n",
    "    gain = gini(data) - pos * gini(data[data[attr] == 1]) - neg * gini(data[data[attr] == 0])\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(trainingSet, testSet, keys):\n",
    "    root = TreeNode(-1, [])\n",
    "    root.expand(trainingSet, keys, 1, DEPTH_LIMIT)\n",
    "    return root\n",
    "\n",
    "def predict(node, data):\n",
    "    if node.is_leaf():\n",
    "        return node.val\n",
    "    else:\n",
    "        if data[node.val] == 0:\n",
    "            return predict(node.left, data)\n",
    "        else:\n",
    "            return predict(node.right, data)\n",
    "\n",
    "def get_accuracy_dt(root, trainingSet, testSet):\n",
    "    count_train, total_train = 0, len(trainingSet)\n",
    "    count_test, total_test = 0, len(testSet)\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    predictions = []\n",
    "    Y = np.array(train_labels)\n",
    "    # Training accuracy\n",
    "    for index, row in trainingSet.iterrows():\n",
    "        predictions.append(predict(root, row)) \n",
    "        if int(predictions[index]) == Y[index]:\n",
    "            count_train += 1\n",
    "    \n",
    "    training_accuracy = 1.0 * count_train/total_train\n",
    "    print 'Training Accuracy DT:', '%.2f' % training_accuracy\n",
    "    \n",
    "    predictions = []\n",
    "    Y = np.array(test_labels)\n",
    "\n",
    "    # Test accuracy\n",
    "    for index, row in testSet.iterrows():\n",
    "        predictions.append(predict(root, row))\n",
    "        if predictions[index] == Y[index]:\n",
    "            count_test += 1\n",
    "\n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy DT:', '%.2f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(trainingSet, testSet, keys):\n",
    "    root_bagging = []\n",
    "    for i in range(30):\n",
    "        train = trainingSet.sample(frac = 1.0, replace=True)\n",
    "        root = TreeNode(-1, [])\n",
    "        root.expand(train, keys, 2, DEPTH_LIMIT)\n",
    "        root_bagging.append(root)\n",
    "    return root_bagging\n",
    "\n",
    "def get_accuracy_bagging(root, trainingSet, testSet):\n",
    "    count_train, total_train = 0, len(trainingSet)\n",
    "    count_test, total_test = 0, len(testSet)\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    predictions = [0 for i in range(len(trainingSet))]\n",
    "    \n",
    "    Y = np.array(train_labels)\n",
    "    # Training accuracy\n",
    "    for r in root:\n",
    "        for index, row in trainingSet.iterrows():\n",
    "            predictions[index] += int(predict(r, row))\n",
    "    #print predictions\n",
    "\n",
    "    for i in range(len(trainingSet)):\n",
    "        if predictions[i] > 15 and Y[i] == 1:\n",
    "            count_train += 1\n",
    "        elif predictions[i] <= 15 and Y[i] == 0:\n",
    "            count_train += 1\n",
    "    \n",
    "    training_accuracy = 1.0 * count_train/total_train\n",
    "    print 'Training Accuracy BT:', '%.2f' % training_accuracy\n",
    "    \n",
    "    predictions = [0 for i in range(len(testSet))]\n",
    "    Y = np.array(test_labels)\n",
    "\n",
    "    # Test accuracy\n",
    "    for r in root:\n",
    "        for index, row in testSet.iterrows():\n",
    "            predictions[index] += int(predict(r, row))\n",
    "\n",
    "    for i in range(len(testSet)):\n",
    "        if predictions[i] > 15 and Y[i] == 1:\n",
    "            count_test += 1\n",
    "        elif predictions[i] <= 15 and Y[i] == 0:\n",
    "            count_test += 1\n",
    "\n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy BT:', '%.2f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForests(trainingSet, testSet, keys):\n",
    "    root_rf = []\n",
    "    for i in range(30):\n",
    "        train = trainingSet.sample(frac = 1.0, replace=True)\n",
    "        root = TreeNode(-1, [])\n",
    "        root.expand(train, keys, 3, DEPTH_LIMIT)\n",
    "        root_rf.append(root)\n",
    "        #get_accuracy_dt(root, trainingSet, testSet)\n",
    "    return root_rf\n",
    "    \n",
    "def get_accuracy_rf(root, trainingSet, testSet):\n",
    "    count_train, total_train = 0, len(trainingSet)\n",
    "    count_test, total_test = 0, len(testSet)\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    predictions = [0 for i in range(len(trainingSet))]\n",
    "    \n",
    "    Y = np.array(train_labels)\n",
    "    # Training accuracy\n",
    "    for r in root:\n",
    "        for index, row in trainingSet.iterrows():\n",
    "            predictions[index] += int(predict(r, row))\n",
    "    #print predictions\n",
    "\n",
    "    for i in range(len(trainingSet)):\n",
    "        if predictions[i] > 15 and Y[i] == 1:\n",
    "            count_train += 1\n",
    "        elif predictions[i] <= 15 and Y[i] == 0:\n",
    "            count_train += 1\n",
    "    \n",
    "    training_accuracy = 1.0 * count_train/total_train\n",
    "    print 'Training Accuracy RF:', '%.2f' % training_accuracy\n",
    "    \n",
    "    predictions = [0 for i in range(len(testSet))]\n",
    "    Y = np.array(test_labels)\n",
    "\n",
    "    # Test accuracy\n",
    "    for r in root:\n",
    "        for index, row in testSet.iterrows():\n",
    "            predictions[index] += int(predict(r, row))\n",
    "\n",
    "    for i in range(len(testSet)):\n",
    "        if predictions[i] > 15 and Y[i] == 1:\n",
    "            count_test += 1\n",
    "        elif predictions[i] <= 15 and Y[i] == 0:\n",
    "            count_test += 1\n",
    "\n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy RF:', '%.2f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy RF: 0.76\n",
      "Test Accuracy RF: 0.73\n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "keys = trainingSet.keys()\n",
    "keys = keys.drop('decision')\n",
    "\n",
    "if modelIdx == 1:\n",
    "    root = decisionTree(trainingSet, testSet, keys)\n",
    "    get_accuracy_dt(root, trainingSet, testSet)\n",
    "elif modelIdx == 2:\n",
    "    root = bagging(trainingSet, testSet, keys)\n",
    "    get_accuracy_bagging(root, trainingSet, testSet)\n",
    "elif modelIdx == 3:\n",
    "    root = randomForests(trainingSet, testSet, keys)\n",
    "    get_accuracy_rf(root, trainingSet, testSet)\n",
    "else:\n",
    "    print 'modelIdx error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
