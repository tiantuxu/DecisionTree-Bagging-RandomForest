{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[1] = 'trainingSet.csv'\n",
    "sys.argv[2] = 'testSet.csv'\n",
    "\n",
    "trainingDataFilename = sys.argv[1]\n",
    "testDataFilename = sys.argv[2]\n",
    "# modelIdx = int(sys.argv[3])\n",
    "modelIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_LIMIT = 8\n",
    "SAMPLE_LIMIT = 50\n",
    "class TreeNode(object):\n",
    "    def __init__(self, class_label, lineage):\n",
    "        self.val = class_label\n",
    "        self.lineage = lineage\n",
    "        #self.attr = attr\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return ((self.left is None) or (self.right is None))\n",
    "\n",
    "    def expand(self, data, features,\n",
    "               depth=DEPTH_LIMIT, downsampling_power=1):\n",
    "#         if not len(data):\n",
    "#             self.val = -1\n",
    "#             return\n",
    "#         class_col = data['decision']\n",
    "#         print class_col\n",
    "        class_label = int(len(data[data['decision'] == 1]) > len(data[data['decision'] == 0]))\n",
    "        #print class_label\n",
    "        available_features = [f for f in features if f not in self.lineage]\n",
    "#         available_features = \\\n",
    "#             sample(eligible_features,\n",
    "#                    int(round(len(eligible_features)**downsampling_power)))\n",
    "        if len(self.lineage) < depth and len(data) > 50:\n",
    "            ginis = {k: gini(data) for k in available_features}\n",
    "            best_feature = max(ginis, key=ginis.get)\n",
    "            #print best_feature, ginis[best_feature]\n",
    "            left_data = data[data[best_feature] == 0]\n",
    "            right_data = data[data[best_feature] == 1]\n",
    "            \n",
    "            self.val = best_feature\n",
    "            self.left = TreeNode(class_label, self.lineage + [best_feature])\n",
    "            self.left.expand(left_data, features, depth=depth,\n",
    "                             downsampling_power=downsampling_power)\n",
    "            self.right = TreeNode(class_label, self.lineage + [best_feature])\n",
    "            self.right.expand(right_data, features, depth=depth,\n",
    "                              downsampling_power=downsampling_power)\n",
    "        else:\n",
    "            #print 'leaf'\n",
    "            self.val = class_label\n",
    "            \n",
    "def gini(data):\n",
    "    gini = 0.0\n",
    "    total = len(data)\n",
    "    pos = 1.0 * data['decision'].value_counts()[0]/total\n",
    "    neg = 1.0 * data['decision'].value_counts()[1]/total\n",
    "\n",
    "    return 1 - pos ** 2 - neg ** 2, pos, neg\n",
    "\n",
    "def get_gini_gain(data, attr):\n",
    "    gain = gini(data) - pos * gini(data[data[attr] == 1]) - neg * gini(data[data[attr] == 1])\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(trainingSet, testSet, keys):\n",
    "    print 'decisionTree'\n",
    "    #ginis = {i: get_gini_gain(trainingSet, key) for key in keys}\n",
    "    #best_feature = max(ginis, key=ginis.get)\n",
    "    root = TreeNode(-1, [])\n",
    "    root.expand(trainingSet, keys, DEPTH_LIMIT, 1)\n",
    "    \n",
    "    return root\n",
    "\n",
    "def predict(node, data):\n",
    "    if node.is_leaf():\n",
    "        return node.val\n",
    "    else:\n",
    "        if data[node.val] == '0':\n",
    "            predict(node.left, data)\n",
    "        else:\n",
    "            predict(node.right, data)\n",
    "\n",
    "def get_accuracy_dt(root, trainingSet, testSet):\n",
    "    count_train, total_train = 0, len(trainingSet)\n",
    "    count_test, total_test = 0, len(testSet)\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    predictions = []\n",
    "    Y = np.array(train_labels)\n",
    "    # Training accuracy\n",
    "    for index, row in trainingSet.iterrows():\n",
    "        predictions.append(predict(root, row)) \n",
    "        #print predict(root, row)\n",
    "        if predictions[index] == int(Y[index]):\n",
    "            count_train += 1\n",
    "\n",
    "    training_accuracy = 1.0 * count_train/total_train\n",
    "    print 'Training Accuracy DT:', '%.2f' % training_accuracy\n",
    "    \n",
    "    predictions = []\n",
    "    Y = np.array(test_labels)\n",
    "\n",
    "    # Training accuracy\n",
    "    for index, row in testSet.iterrows():\n",
    "        predictions.append(predict(root, row))\n",
    "        #print predict(root, row)\n",
    "        if predictions[index] == int(Y[index]):\n",
    "            count_test += 1\n",
    "\n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy DT:', '%.2f' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(trainingSet, testSet):\n",
    "    print 'bagging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForests(trainingSet, testSet):\n",
    "    print 'randomForests'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisionTree\n",
      "art\n",
      "Training Accuracy DT: 0.00\n",
      "Test Accuracy DT: 0.00\n"
     ]
    }
   ],
   "source": [
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "keys = trainingSet.keys()\n",
    "keys = keys.drop('decision')\n",
    "\n",
    "if modelIdx == 1:\n",
    "    root = decisionTree(trainingSet, testSet, keys)\n",
    "    print root.val\n",
    "    get_accuracy_dt(root, trainingSet, testSet)\n",
    "elif modelIdx == 2:\n",
    "    bagging(trainingSet, testSet)\n",
    "elif modelIdx == 3:\n",
    "    randomForests(trainingSet, testSet)\n",
    "else:\n",
    "    print 'modelIdx error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
